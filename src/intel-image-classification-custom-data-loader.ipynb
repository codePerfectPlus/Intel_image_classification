{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\" Training scrip(t in Tensorflow \"\"\"\nimport os\nimport logging\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras import optimizers, losses, metrics\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.vgg16 import preprocess_input","metadata":{"_uuid":"0f20338b-8da4-4982-becb-b90ecd41cf04","_cell_guid":"972ab640-c107-4383-a130-35034b721bf8","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-09-08T04:41:11.295381Z","iopub.execute_input":"2021-09-08T04:41:11.295712Z","iopub.status.idle":"2021-09-08T04:41:15.498233Z","shell.execute_reply.started":"2021-09-08T04:41:11.295639Z","shell.execute_reply":"2021-09-08T04:41:15.497084Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"train_dir = \"../input/intel-image-classification/seg_train/seg_train\"\ntest_dir = \"../input/intel-image-classification/seg_test/seg_test\"\nepochs=50\nimg_size = (150, 150)\nimg_shape = (150, 150, 3)\nbatch_size = 256\nnum_classes = len(os.listdir(train_dir))\nidx_to_name = os.listdir(train_dir)\nname_to_idx = dict([(v, k) for k, v in enumerate(idx_to_name)])","metadata":{"execution":{"iopub.status.busy":"2021-09-08T04:41:15.499880Z","iopub.execute_input":"2021-09-08T04:41:15.500212Z","iopub.status.idle":"2021-09-08T04:41:15.517896Z","shell.execute_reply.started":"2021-09-08T04:41:15.500178Z","shell.execute_reply":"2021-09-08T04:41:15.516877Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"name_to_idx","metadata":{"execution":{"iopub.status.busy":"2021-09-08T04:41:15.519474Z","iopub.execute_input":"2021-09-08T04:41:15.520000Z","iopub.status.idle":"2021-09-08T04:41:15.528571Z","shell.execute_reply.started":"2021-09-08T04:41:15.519958Z","shell.execute_reply":"2021-09-08T04:41:15.527486Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"{'mountain': 0,\n 'street': 1,\n 'buildings': 2,\n 'sea': 3,\n 'forest': 4,\n 'glacier': 5}"},"metadata":{}}]},{"cell_type":"code","source":"def data_to_df(data_dir, subset=None):\n    df = pd.DataFrame()\n    filenames = []\n    labels = []\n    \n    for dataset in os.listdir(data_dir):\n        img_list = os.listdir(os.path.join(data_dir, dataset))\n        label = name_to_idx[dataset]\n        \n        for image in img_list:\n            filenames.append(os.path.join(data_dir, dataset, image))\n            labels.append(label)\n        \n    df[\"filenames\"] = filenames\n    df[\"labels\"] = labels\n    \n    if subset == \"train\":\n        train_df, val_df = train_test_split(df, train_size=0.8, shuffle=True,\n                                            random_state=10)\n        return train_df, val_df\n    \n    return df\n\nprint(\"Converting data directory to dataframe\")\ntrain_df, val_df = data_to_df(train_dir, subset=\"train\")","metadata":{"execution":{"iopub.status.busy":"2021-09-08T04:50:17.105257Z","iopub.execute_input":"2021-09-08T04:50:17.105599Z","iopub.status.idle":"2021-09-08T04:50:18.564978Z","shell.execute_reply.started":"2021-09-08T04:50:17.105557Z","shell.execute_reply":"2021-09-08T04:50:18.564061Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"Converting data directory to dataframe\n","output_type":"stream"}]},{"cell_type":"code","source":"class CustomDataGenerator(tf.keras.utils.Sequence):\n\n    ''' Custom DataGenerator to load img \n    \n    Arguments:\n        data_frame = pandas data frame in filenames and labels format\n        batch_size = divide data in batches\n        shuffle = shuffle data before loading\n        img_shape = image shape in (h, w, d) format\n        augmentation = data augmentation to make model rebust to overfitting\n    \n    Output:\n        Img: numpy array of image\n        label : output label for image\n    '''\n    \n    def __init__(self, data_frame, batch_size=10, img_shape=None, augmentation=True, num_classes=None):\n        self.data_frame = data_frame\n        self.train_len = self.data_frame.shape[0]\n        self.batch_size = batch_size\n        self.img_shape = img_shape\n        self.num_classes = num_classes\n        print(f\"Found {self.data_frame.shape[0]} images belonging to {self.num_classes} classes\")\n\n    def __len__(self):\n        self.data_frame = shuffle(self.data_frame)\n        return int(self.train_len/self.batch_size)\n\n    def on_epoch_end(self):\n        # fix on epoch end it's not working, adding shuffle in len for alternative\n        pass\n    \n    def __data_augmentation(self, img):\n        img = tf.keras.preprocessing.image.random_shift(img, 0.2, 0.3)\n        img = tf.image.random_flip_left_right(img)\n        img = tf.image.random_flip_up_down(img)\n        return img\n        \n    def __get_image(self, file_id):\n        img = np.asarray(Image.open(file_id))\n        img = np.resize(img, self.img_shape)\n        #img = self.__data_augmentation(img)\n        img = preprocess_input(img)\n\n        return img\n\n    def __get_label(self, label_id):\n        return label_id\n\n    def __getitem__(self, idx):\n        batch_x = self.data_frame[\"filenames\"][idx * self.batch_size:(idx + 1) * self.batch_size]\n        batch_y = self.data_frame[\"labels\"][idx * self.batch_size:(idx + 1) * self.batch_size]\n        # read your data here using the batch lists, batch_x and batch_y\n        x = [self.__get_image(file_id) for file_id in batch_x] \n        y = [self.__get_label(label_id) for label_id in batch_y]\n\n        return np.array(x), np.array(y)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T04:50:18.566523Z","iopub.execute_input":"2021-09-08T04:50:18.566857Z","iopub.status.idle":"2021-09-08T04:50:18.578877Z","shell.execute_reply.started":"2021-09-08T04:50:18.566820Z","shell.execute_reply":"2021-09-08T04:50:18.577893Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"print(\"creating train and validation data\")\ntrain_data = CustomDataGenerator(train_df, \n                                 batch_size=batch_size, \n                                 img_shape=img_shape,\n                                 num_classes=num_classes\n                                )\nval_data = CustomDataGenerator(val_df, \n                               batch_size=batch_size, img_shape=img_shape, num_classes=num_classes)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T04:50:19.249511Z","iopub.execute_input":"2021-09-08T04:50:19.249863Z","iopub.status.idle":"2021-09-08T04:50:19.256027Z","shell.execute_reply.started":"2021-09-08T04:50:19.249826Z","shell.execute_reply":"2021-09-08T04:50:19.254746Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"creating train and validation data\nFound 11227 images belonging to 6 classes\nFound 2807 images belonging to 6 classes\n","output_type":"stream"}]},{"cell_type":"code","source":"def build_model(img_shape):\n    inputs = layers.Input(shape=img_shape)\n    out = layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(inputs)\n    out = layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(out)\n    out = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(out)\n\n    out = layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(out)\n    out = layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(out)\n    out = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(out)\n\n    out = layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(out)\n    out = layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(out)\n    out = layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(out)\n    out = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(out)\n\n    out = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(out)\n    out = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(out)\n    out = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(out)\n    out = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(out)\n\n    out = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(out)\n    out = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(out)\n    out = layers.Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(out)\n    out = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(out)\n\n    out = layers.GlobalAveragePooling2D()(out)\n    out = layers.Dense(128, activation=\"relu\")(out)\n    out = layers.Dropout(0.5)(out)\n    outputs = layers.Dense(6, activation=\"softmax\")(out)\n    \n    return tf.keras.Model(inputs, outputs, name=\"VGG16\")","metadata":{"execution":{"iopub.status.busy":"2021-09-08T04:50:22.273780Z","iopub.execute_input":"2021-09-08T04:50:22.274170Z","iopub.status.idle":"2021-09-08T04:50:22.288374Z","shell.execute_reply.started":"2021-09-08T04:50:22.274136Z","shell.execute_reply":"2021-09-08T04:50:22.287540Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"model = build_model(img_shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T04:50:24.575551Z","iopub.execute_input":"2021-09-08T04:50:24.575925Z","iopub.status.idle":"2021-09-08T04:50:24.694254Z","shell.execute_reply.started":"2021-09-08T04:50:24.575888Z","shell.execute_reply":"2021-09-08T04:50:24.693452Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-09-08T04:50:24.695655Z","iopub.execute_input":"2021-09-08T04:50:24.696000Z","iopub.status.idle":"2021-09-08T04:50:24.713373Z","shell.execute_reply.started":"2021-09-08T04:50:24.695965Z","shell.execute_reply":"2021-09-08T04:50:24.712620Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Model: \"VGG16\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_5 (InputLayer)         [(None, 150, 150, 3)]     0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n_________________________________________________________________\nglobal_average_pooling2d_4 ( (None, 512)               0         \n_________________________________________________________________\ndense_8 (Dense)              (None, 128)               65664     \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_9 (Dense)              (None, 6)                 774       \n=================================================================\nTotal params: 14,781,126\nTrainable params: 14,781,126\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"optimizer = optimizers.Adam()\nloss_fn = losses.SparseCategoricalCrossentropy(from_logits=True)\ntrain_acc_metrics = metrics.SparseCategoricalAccuracy()\nval_acc_metrics = metrics.SparseCategoricalAccuracy()","metadata":{"execution":{"iopub.status.busy":"2021-09-08T04:50:25.520708Z","iopub.execute_input":"2021-09-08T04:50:25.521098Z","iopub.status.idle":"2021-09-08T04:50:25.541325Z","shell.execute_reply.started":"2021-09-08T04:50:25.521057Z","shell.execute_reply":"2021-09-08T04:50:25.540477Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef train_step(x, y):\n    with tf.GradientTape() as tape:\n        logits = model(x, training=True)\n        loss_value = loss_fn(y, logits)\n    grads = tape.gradient(loss_value, model.trainable_weights)\n    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n    train_acc_metrics.update_state(y, logits)\n    return loss_value\n\n@tf.function\ndef test_step(x, y):\n    val_logits = model(x, training=False)\n    val_acc_metrics.update_state(y, val_logits)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T04:50:26.572256Z","iopub.execute_input":"2021-09-08T04:50:26.572574Z","iopub.status.idle":"2021-09-08T04:50:26.579768Z","shell.execute_reply.started":"2021-09-08T04:50:26.572544Z","shell.execute_reply":"2021-09-08T04:50:26.578863Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"epochs = 10\nimport time\nfor epoch in range(epochs):\n    print(f\"Epoch :{epoch}/{epochs}\")\n    start_time = time.perf_counter()\n    for step, (x_batch_train, y_batch_train) in enumerate(train_data):\n        loss_value = train_step(x_batch_train, y_batch_train)\n        \n        if (step % 50) == 0: \n            print(f\"Step: {step} Training loss :{loss_value}\")\n            print(f\"Seen so far: {(step + 1) * batch_size} samples\") \n    \n    train_acc = train_acc_metrics.result()\n    print(\"Training Accuracy:\", float(train_acc))\n    train_acc_metrics.reset_states()\n\n    for x_batch_val, y_batch_val in val_data:\n        test_step(x_batch_val, y_batch_val)\n    \n    val_acc = val_acc_metrics.result()\n    print(\"Validation Accuracy: \", float(val_acc))\n    val_acc_metrics.reset_states()\n\n    print(\"Time Taken\", time.perf_counter() - start_time)\n    print(\"*\"*80)","metadata":{"execution":{"iopub.status.busy":"2021-09-08T04:50:26.809437Z","iopub.execute_input":"2021-09-08T04:50:26.809860Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch :0/10\nStep: 0 Training loss :1.7991528511047363\nSeen so far: 256 samples\nTraining Accuracy: 0.17641715705394745\nValidation Accuracy:  0.17656250298023224\nTime Taken 87.83492912600002\n********************************************************************************\nEpoch :1/10\nStep: 0 Training loss :1.788527011871338\nSeen so far: 256 samples\nTraining Accuracy: 0.2798873484134674\nValidation Accuracy:  0.46367186307907104\nTime Taken 39.725649489000034\n********************************************************************************\nEpoch :2/10\nStep: 0 Training loss :1.3920685052871704\nSeen so far: 256 samples\nTraining Accuracy: 0.48046875\nValidation Accuracy:  0.5492187738418579\nTime Taken 38.755842171999916\n********************************************************************************\nEpoch :3/10\nStep: 0 Training loss :1.1463885307312012\nSeen so far: 256 samples\nTraining Accuracy: 0.570857584476471\nValidation Accuracy:  0.592578113079071\nTime Taken 38.14275528600001\n********************************************************************************\nEpoch :4/10\nStep: 0 Training loss :0.9582701921463013\nSeen so far: 256 samples\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(optimizer=optimizer, loss=loss_fn)\nmodel.save(\"saved_model\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = data_to_df(test_dir)\ntest_data = CustomDataGenerator(test_df, \n                               batch_size=batch_size, img_shape=img_shape, num_classes=num_classes)","metadata":{},"execution_count":null,"outputs":[]}]}